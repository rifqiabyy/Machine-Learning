{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Padding and Stride.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNlX4Ac58nS00QCbiZWypoM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rifqiabyy/Machine-Learning/blob/main/week%2011%20ML/Padding_and_Stride.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the following example, we create a two-dimensional convolutional layer with a height and width of 3 and apply 1 pixel of padding on all sides. Given an input with a height and width of 8, we find that the height and width of the output is also 8."
      ],
      "metadata": {
        "id": "FDdRVQhhtpdv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Bm-6e7RtbPy",
        "outputId": "6225aa7c-579d-4a52-c857-93a03cf3e10a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([8, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "# We define a convenience function to calculate the convolutional layer. This\n",
        "# function initializes the convolutional layer weights and performs\n",
        "# corresponding dimensionality elevations and reductions on the input and\n",
        "# output\n",
        "def comp_conv2d(conv2d, X):\n",
        "    # Here (1, 1) indicates that the batch size and the number of channels\n",
        "    # are both 1\n",
        "    X = tf.reshape(X, (1, ) + X.shape + (1, ))\n",
        "    Y = conv2d(X)\n",
        "    # Exclude the first two dimensions that do not interest us: examples and\n",
        "    # channels\n",
        "    return tf.reshape(Y, Y.shape[1:3])\n",
        "# Note that here 1 row or column is padded on either side, so a total of 2\n",
        "# rows or columns are added\n",
        "conv2d = tf.keras.layers.Conv2D(1, kernel_size=3, padding='same')\n",
        "X = tf.random.uniform(shape=(8, 8))\n",
        "comp_conv2d(conv2d, X).shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "When the height and width of the convolution kernel are different, we can make the output and input have the same height and width by setting different padding numbers for height and width."
      ],
      "metadata": {
        "id": "RWqqat53tv07"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conv2d = tf.keras.layers.Conv2D(1, kernel_size=(5, 3), padding='same')\n",
        "comp_conv2d(conv2d, X).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aAxJsjIDtwVJ",
        "outputId": "49fe336a-9a8e-482e-ca3e-afc55b722ae2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([8, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Stride**\n",
        "\n",
        "Below, we set the strides on both the height and width to 2, thus halving the input height and width."
      ],
      "metadata": {
        "id": "UplQcSN2t0ro"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conv2d = tf.keras.layers.Conv2D(1, kernel_size=3, padding='same', strides=2)\n",
        "comp_conv2d(conv2d, X).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZxsxgPmBt2AQ",
        "outputId": "6a61b38d-986d-4283-b5ab-5166ab33d9c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([4, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conv2d = tf.keras.layers.Conv2D(1, kernel_size=(3,5), padding='valid',\n",
        "                                strides=(3, 4))\n",
        "comp_conv2d(conv2d, X).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wnYwQqZt4bZ",
        "outputId": "7ac74af9-75d8-4883-bb71-3014d18b4ce2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([2, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Summary**\n",
        "\n",
        "Padding can increase the height and width of the output. This is often used to give the output the same height and width as the input.\n",
        "\n",
        "The stride can reduce the resolution of the output, for example reducing the height and width of the output to only 1/n of the height and width of the input ( n is an integer greater than 1 ).\n",
        "\n",
        "Padding and stride can be used to adjust the dimensionality of the data effectively."
      ],
      "metadata": {
        "id": "C4kWSfh7t697"
      }
    }
  ]
}